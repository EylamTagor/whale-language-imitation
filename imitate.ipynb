{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ab2df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from whale_imitation import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326ab234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             REC  nClicks  Duration      ICI1      ICI2      ICI3      ICI4  \\\n",
       " 0  sw061b001_124       17  0.927792  0.033950  0.036117  0.048867  0.048908   \n",
       " 1  sw061b001_124       20  1.092992  0.032817  0.039358  0.045325  0.049933   \n",
       " 2  sw061b001_124        5  0.898250  0.275850  0.286783  0.197400  0.138217   \n",
       " 3  sw061b001_124        5  0.865575  0.262275  0.276883  0.183333  0.143083   \n",
       " 4  sw061b001_124        5  0.858317  0.266675  0.269358  0.178325  0.143958   \n",
       " \n",
       "        ICI5      ICI6      ICI7  ...  ICI21  ICI22  ICI23  ICI24  ICI25  \\\n",
       " 0  0.042275  0.040483  0.040975  ...    0.0    0.0    0.0    0.0    0.0   \n",
       " 1  0.044083  0.044783  0.043683  ...    0.0    0.0    0.0    0.0    0.0   \n",
       " 2  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       " 3  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       " 4  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       " \n",
       "    ICI26  ICI27  ICI28  Whale      TsTo  \n",
       " 0    0.0    0.0    0.0      1  126.0372  \n",
       " 1    0.0    0.0    0.0      1  128.3256  \n",
       " 2    0.0    0.0    0.0      1  131.7476  \n",
       " 3    0.0    0.0    0.0      1  135.5877  \n",
       " 4    0.0    0.0    0.0      1  139.5217  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       " (3840, 33))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH = \"sperm-whale-dialogues.csv\"\n",
    "\n",
    "assert os.path.exists(CSV_PATH), f\"Missing {CSV_PATH}. Put it next to the notebook or update CSV_PATH.\"\n",
    "\n",
    "df = load_csv(CSV_PATH)\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f432ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num conversations (REC): 219\n",
      "Train RECs: 197\n",
      "Val RECs: 22\n",
      "Test RECs: 0\n"
     ]
    }
   ],
   "source": [
    "train_recs, val_recs, test_recs = split_recs(df, val_frac=0.1, test_frac=0.0, seed=0)\n",
    "\n",
    "print(\"Num conversations (REC):\", df[\"REC\"].nunique())\n",
    "print(\"Train RECs:\", len(train_recs))\n",
    "print(\"Val RECs:\", len(val_recs))\n",
    "print(\"Test RECs:\", len(test_recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8f79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train episodes (rows): 3521\n",
      "Val episodes (rows): 319\n",
      "Num whales (mapped): 10\n",
      "ICI norm mean/std: -1.8894754295816543 0.8070952322128051\n"
     ]
    }
   ],
   "source": [
    "cfg = BCConfig(\n",
    "    hidden_size=256,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    use_log_ici=True,\n",
    ")\n",
    "\n",
    "train_ds = WhaleBCDataset(CSV_PATH, cfg=cfg, recs=train_recs)\n",
    "val_ds   = WhaleBCDataset(CSV_PATH, cfg=cfg, recs=val_recs, ici_mean=train_ds.ici_mean, ici_std=train_ds.ici_std)\n",
    "\n",
    "print(\"Train episodes (rows):\", len(train_ds))\n",
    "print(\"Val episodes (rows):\", len(val_ds))\n",
    "print(\"Num whales (mapped):\", train_ds.n_whales)\n",
    "print(\"ICI norm mean/std:\", train_ds.ici_mean, train_ds.ici_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d756a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_TRAIN = 32\n",
    "BATCH_VAL   = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_TRAIN,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_bc(b, cfg=cfg),\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_VAL,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda b: collate_bc(b, cfg=cfg),\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44caf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUBCModel(\n",
       "  (whale_emb): Embedding(10, 32)\n",
       "  (type_emb): Embedding(4, 16)\n",
       "  (gru): GRU(49, 256, batch_first=True)\n",
       "  (head_eos): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (head_ici): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRUBCModel(n_whales=train_ds.n_whales, cfg=cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beaf45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_total': 1.7427553415298462,\n",
       " 'loss_eos': 0.7539610266685486,\n",
       " 'loss_ici': 0.9887943267822266}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_val = evaluate_bc(model, val_loader, device=device)\n",
    "pre_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415d1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eylam/.pyenv/versions/3.11.6/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BC] ep 1/10 train_total=0.7314 train_eos=0.3216 train_ici=0.4099 | val_total=0.4460 val_eos=0.1657 val_ici=0.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BC] ep 2/10 train_total=0.4285 train_eos=0.1953 train_ici=0.2332 | val_total=0.3841 val_eos=0.1293 val_ici=0.2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BC] ep 3/10 train_total=0.3584 train_eos=0.1459 train_ici=0.2125 | val_total=0.3379 val_eos=0.1067 val_ici=0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BC] ep 4/10 train_total=0.3798 train_eos=0.1305 train_ici=0.2493 | val_total=0.3318 val_eos=0.1011 val_ici=0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BC] ep 5/10 train_total=0.3150 train_eos=0.1134 train_ici=0.2016 | val_total=0.3212 val_eos=0.0963 val_ici=0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mtrain_bc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m history[:\u001b[32m2\u001b[39m], history[-\u001b[32m2\u001b[39m:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/whale-language-imitation/whale_imitation.py:557\u001b[39m, in \u001b[36mtrain_bc\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, lr, device, show_progress, log_every)\u001b[39m\n\u001b[32m    549\u001b[39m loss, stats = compute_losses(\n\u001b[32m    550\u001b[39m     eos_logits, ici_pred,\n\u001b[32m    551\u001b[39m     next_is_eos, next_ici_feat,\n\u001b[32m    552\u001b[39m     loss_mask_eos, loss_mask_ici,\n\u001b[32m    553\u001b[39m     cfg,\n\u001b[32m    554\u001b[39m )\n\u001b[32m    556\u001b[39m opt.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cfg.grad_clip_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m cfg.grad_clip_norm > \u001b[32m0\u001b[39m:\n\u001b[32m    559\u001b[39m     nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = train_bc(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "history[:2], history[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa31002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [h[\"epoch\"] for h in history]\n",
    "val_total = [h.get(\"val_loss_total\", np.nan) for h in history]\n",
    "val_eos   = [h.get(\"val_loss_eos\", np.nan) for h in history]\n",
    "val_ici   = [h.get(\"val_loss_ici\", np.nan) for h in history]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, val_total, label=\"val_total\")\n",
    "plt.plot(epochs, val_eos, label=\"val_eos\")\n",
    "plt.plot(epochs, val_ici, label=\"val_ici\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.title(\"BC validation losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53013fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an episode index from val set\n",
    "episode_index = 0\n",
    "\n",
    "ex = val_ds[episode_index]\n",
    "\n",
    "# Find SOC index; everything before it is history\n",
    "soc_idx = ex[\"tok_types\"].index(cfg.TOK_SOC)\n",
    "\n",
    "history_tokens = list(zip(\n",
    "    ex[\"whale_ids\"][:soc_idx],\n",
    "    ex[\"tok_types\"][:soc_idx],\n",
    "    ex[\"ici_feats\"][:soc_idx],\n",
    "))\n",
    "\n",
    "current_whale = ex[\"whale_ids\"][soc_idx]\n",
    "\n",
    "gen = rollout_coda(\n",
    "    model=model,\n",
    "    history_tokens=history_tokens,\n",
    "    current_whale=current_whale,\n",
    "    max_len=cfg.max_ici_cols,  # max ICIs to generate\n",
    "    ici_mean=val_ds.ici_mean,\n",
    "    ici_std=val_ds.ici_std,\n",
    "    eos_threshold=0.5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Generated ICI count:\", len(gen))\n",
    "print(\"Generated ICIs:\", gen[:10], \"...\" if len(gen) > 10 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the real coda ICIs for this episode from the dataset tensors\n",
    "# ex contains normalized feats; convert back to raw ICIs for the real ICIs after SOC until EOS.\n",
    "\n",
    "real_feats = []\n",
    "for tt, f in zip(ex[\"tok_types\"][soc_idx+1:], ex[\"ici_feats\"][soc_idx+1:]):\n",
    "    if tt == cfg.TOK_EOS:\n",
    "        break\n",
    "    if tt == cfg.TOK_ICI:\n",
    "        real_feats.append(float(f))\n",
    "\n",
    "from whale_imitation import feat_to_ici\n",
    "\n",
    "real_ici = [feat_to_ici(f, cfg, val_ds.ici_mean, val_ds.ici_std) for f in real_feats]\n",
    "\n",
    "print(\"Real ICI count:\", len(real_ici))\n",
    "print(\"Real ICIs:\", real_ici[:10], \"...\" if len(real_ici) > 10 else \"\")\n",
    "\n",
    "# Simple side-by-side for first min length\n",
    "m = min(len(real_ici), len(gen))\n",
    "pairs = list(zip(real_ici[:m], gen[:m]))\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whale_imitation import (\n",
    "    GRUDiscriminator, DiscConfig,\n",
    "    make_disc_loader_from_dataset,\n",
    "    train_discriminator, evaluate_discriminator,\n",
    ")\n",
    "\n",
    "# How many episode pairs to sample for the discriminator dataset\n",
    "NUM_PAIRS = min(1000, len(val_ds))   # increase if you have enough data\n",
    "DISC_BATCH = 32\n",
    "MAX_GEN_LEN = cfg.max_ici_cols\n",
    "EOS_THRESH = 0.5\n",
    "\n",
    "disc_loader = make_disc_loader_from_dataset(\n",
    "    ds=val_ds,\n",
    "    bc_model=model,\n",
    "    num_pairs=NUM_PAIRS,\n",
    "    batch_size=DISC_BATCH,\n",
    "    max_len=MAX_GEN_LEN,\n",
    "    eos_threshold=EOS_THRESH,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    device_for_generation=device,   # generation can be on GPU if available\n",
    ")\n",
    "\n",
    "print(\"Discriminator examples (real+fake):\", 2 * NUM_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6480ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_cfg = DiscConfig(\n",
    "    hidden_size=256,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    ")\n",
    "\n",
    "disc = GRUDiscriminator(\n",
    "    n_whales=val_ds.n_whales,\n",
    "    cfg=disc_cfg,\n",
    "    bc_cfg=cfg,\n",
    ")\n",
    "\n",
    "pre = evaluate_discriminator(disc, disc_loader, device=device)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_hist = train_discriminator(\n",
    "    disc=disc,\n",
    "    loader=disc_loader,\n",
    "    epochs=5,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "disc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = evaluate_discriminator(disc, disc_loader, device=device)\n",
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([h[\"epoch\"] for h in disc_hist], [h[\"disc_loss\"] for h in disc_hist])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"disc_loss\")\n",
    "plt.title(\"Discriminator training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Discriminator accuracy:\", post[\"disc_acc\"])\n",
    "print(\"Discriminator AUROC:\", post[\"disc_auc\"])\n",
    "\n",
    "if np.isfinite(post[\"disc_auc\"]):\n",
    "    if post[\"disc_auc\"] > 0.8:\n",
    "        print(\"-> Discriminator can easily tell real vs generated (BC rollouts not very realistic yet).\")\n",
    "    elif post[\"disc_auc\"] > 0.65:\n",
    "        print(\"-> Discriminator has moderate power; BC is partially matching structure.\")\n",
    "    else:\n",
    "        print(\"-> Discriminator struggles to separate; generated episodes look relatively real (or disc is underfit).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
